---
title: "Mood increases during video game play: A naturalistic observational case study of PowerWash Simulator"
description: Computational notebook supporting our manuscript
author:
  - name: Matti Vuorre
    orcid: 0000-0001-5052-066X
    email: mjvuorre@uvt.nl
    url: https://vuorre.netlify.app
    affiliation:
      - ref: a
      - ref: b
  - name: Nick Ballou
    orcid: 0000-0003-4126-0696
    affiliation:
      - ref: b
  - name: Andrew K. Przybylski
    orcid: 0000-0001-5547-2185
    affiliation:
      - ref: b
affiliations:
  - id: a
    name: Tilburg University
  - id: b
    name: University of Oxford
  
date: 2023-09-04
bibliography: bibliography.bib
format:
  pdf: default
  docx: default
  html: default
---

```{r}
#| label: setup
#| include: false

knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  cache = TRUE,
  include = FALSE,
  echo = FALSE
)
```

```{r}
#| label: packages
#| cache: false

library(scales)
library(cmdstanr)
library(posterior)
library(brms)
library(ggstance)
library(patchwork)
library(tidyverse)
```

```{r}
#| label: options
#| cache: false

dir.create("models", FALSE)
options(
  mc.cores = 8,
  brms.backend = "cmdstanr"
)
theme_set(
  theme_linedraw(base_size = 10) +
    theme(
      strip.background = element_rect(fill = NA, color = NA),
      strip.text = element_text(colour = "black", hjust = 0),
      axis.text = element_text(size = rel(0.75)),
      panel.grid = element_blank()
    )
)
```

```{r}
#| label: functions

# Format big numbers with a comma
number2 <- function(x, ...) {
  number(x, ..., big.mark = ",")
}

# Replace extreme percentages
percent2 <- function(x, accuracy = .1) {
  x <- percent(x, accuracy = accuracy)
  x <- if_else(x == "100.0%", ">99.9%", x)
  x <- if_else(x == "0.0%", "<0.1%", x)
  x
}
```

```{r}
#| label: data-download

# Download, unzip data from OSF PWS database
path <- "data-raw/data.zip"
if (!file.exists(path)) {
  dir.create("data-raw", FALSE)
  download.file(
    url = "https://osf.io/download/j48qf/",
    destfile = "data-raw/data.zip"
  )
  dir.create("data", FALSE)
  unzip(
    zipfile = path,
    files = c("data/demographics.csv", "data/study_prompt_answered.csv")
  )
}
```

```{r}
#| label: data-load

dat <- read_csv(
  "data/study_prompt_answered.csv",
  col_select = c(
    pid,
    time = Time_utc,
    duration = CurrentSessionLength,
    prompt = LastStudyPromptType,
    mood = response
  )
) |>
  mutate(
    pid = factor(pid),
    mood = mood / 1000
  )

# Calculate raw data summaries
sraw <- list()
sraw$n_res <- dat |>
  count(prompt)
sraw$n_res_total <- number2(sum(sraw$n_res$n))
sraw$n_res <- sraw$n_res |>
  mutate(n = number2(n)) |>
  pivot_wider(names_from = prompt, values_from = n)
sraw$n_sub <- number2(length(unique(dat$pid)))

# Create sessions using heuristics below
dat <- dat |>
  arrange(pid, time) |>
  mutate(
    i = row_number(),
    # Observation is in a new session if this...
    new_session =
      # is the first total observation,
      i == 1 |
      # session duration is zero,
      (duration == 0) |
      # session is shorter than previous session (ticker has reset),
      (duration < lag(duration, default = 0)) |
      # or if more than 30 minutes since previous observation.
      (time > lag(time) + minutes(30)),
    # Session number is the cumulative sum of new sessions...
    session = cumsum(new_session),
    # ... per person
    .by = pid
  ) |>
  select(-c(i, new_session))


# Filter data:
# Include only wellbeing responses that occurred
# in sessions with both "pre" and "post" measures
dat <- dat |>
  filter(prompt == "Wellbeing") |>
  select(-prompt)

# Count of data with all wellbeing observations
dat_total <- dat |>
  summarise(
    n_total = n(),
    n_players = length(unique(pid))
  )

# Include only sessions with "pre-" and "post" measure(s)
dat <- dat |>
  filter(
    # Session has a wellbeing measure at time = 0
    duration[1] == 0,
    # Session has at least two non-missing wellbeing measures 
    # (e.g. pre + 1 post)
    sum(!is.na(mood)) > 1,
    .by = c(pid, session)
  )

# Count of data to be used in these analyses
dat_filtered <- dat |>
  summarise(
    n_total = n(),
    n_players = length(unique(pid))
  )

# Summary
bind_rows(
  "total" = dat_total,
  "filtered" = dat_filtered,
  .id = "Data"
)

# Summaries of filtered data
s <- list()
s$n_sub <- number2(length(unique(dat$pid)))
s$n_obs <- number2(nrow(dat))
s$n_obs_missing <- number2(nrow(filter(dat, is.na(mood))))
s$n_ses <- number2(nrow(count(dat, pid, session)))
```

# Methods

## Participants

```{r}
#| label: demographics-load

demo <- read_csv(
  "data/demographics.csv",
  col_select = c(pid, country, gender, age)
) |>
  filter(pid %in% unique(dat$pid))

a <- quantile(demo$age, probs = c(.5, .1, .9), na.rm = TRUE)
a <- str_glue("{a[1]} ({a[2]}, {a[3]})")
g <- count(demo, gender, sort = TRUE) |>
  mutate(p = n / sum(n)) |>
  mutate(x = str_glue("{gender} ({number2(n)}, {percent2(p)})"))
n_countries <- length(unique(demo$country[!is.na(demo$country)]))
countries <- count(demo, country, sort = TRUE) |>
  mutate(p = n / sum(n)) |>
  mutate(x = str_glue("{country} ({number2(n)}, {percent2(p)})"))
```

The PowerWash Simulator case study database contains `r sraw$n_res_total` psychological item responses from `r sraw$n_sub` individuals. In this study, we only studied subjective well-being (mood), so did not consider the other five types of item responses in the database (enjoyment, focus, autonomy, competence, and immersion). Therefore, here we used data from `r s$n_sub` participants who provided `r s$n_obs` mood responses (`r s$n_obs_missing` with missing values, which we ignored) from `r s$n_ses` gameplay sessions.

These participants median age (1st & 9th deciles) was `r a`, and four most frequent responses to gender were `r g$x[1:4]`. They hailed from `r n_countries`, with four most represented countries being `r countries$x[1:4]`.

The study procedures were granted ethical approval by Oxford University’s Central University Research Ethics Committee (SSH_OII_CIA_21_011). All participants provided informed consent to participate and reported being 18 years or older.

## Measures

We measured affective well-being with one item.

## Data analysis

```{r}
#| label: data-wrangle-for-analysis

dat <- dat |>
  mutate(
    post = factor(
      row_number() > 1,
      levels = c(FALSE, TRUE),
      labels = c("0", "1")
    ),
    .by = c(pid, session)
  ) |>
  mutate(ps = interaction(pid, session, sep = "_")) |>
  mutate(
    cl = case_when(
      mood == 0 ~ "left",
      mood == 1 ~ "right",
      TRUE ~ "none"
    )
  )
```

Our research question concerned the difference between players’ mood at the beginning of each session (pre-play) and during the subsequent play session (during play). It is important to understand that this contrast does not embed a causal hypothesis: Players could begin (and end) their play ses-sions for whatever reason, and these reasons are likely to confound the pre -- during contrast. For example, a player might come home after a stressful day at work, and sit down to play some PWS. During this play session, their mood would improve because they are at home vs. stressful work environment, and would show as a greater during play mood compared to pre-play mood: Reasons behind starting a play session are likely to contribute to the pre -- during contrast and we are unable to disentangle those from any changes actually caused by play.

We estimated this contrast within a censored three-level hierarchical regression model. We specified a censored gaussian model because mood was measured with a VAS. Ignoring the censoring inherent in VAS responses can confound changes in the mean with changes in the spread of mood, and leave the contrast susceptible to ceiling or floor effects. We then modelled mean mood on an intercept and contrast coded time (pre-play: -0.5; during play: 0.5), and allowed both parameters to vary randomly across players. In addition, we modelled random intercepts over player-sessions because over time, mood is susceptible to myriad other influences. Although equal variances across people in such naturalistic observation seem unlikely, we fixed this parameter to a constant for model identifiability and convergence.

More formally, we modelled each mood response *i* in 1 to `r s$n_obs` from participant *j* in 1 to `r s$n_sub` and participant-session *k* in 1 to `r s$n_ses` with a normal distribution censored at the VAS limits [0, 1]. We then modelled the distribution's mean ($\eta$) on a population-level intercept ($\beta_0$) and contrast of time ($\beta_1$), their random per-player deviations $\alpha$, and a random intercept for player-sessions $\gamma_0$:

\begin{align*}
\text{mood}_{ijk} &\sim \text{CensNormal}(\eta_{ijk}, \sigma^2, 0, 1), \\
\eta_{ijk} &= \alpha_0 + \beta_{0j} +
  (\alpha_1 + \beta_{1j})\text{post}_{ijk} +
  \gamma_{0k}, \\
\begin{bmatrix} \alpha_0 \\ \alpha_1 \end{bmatrix} &\sim 
  \text{MVN}\left(\begin{bmatrix} 0 \\ 0 \end{bmatrix}, 
  \begin{bmatrix} 
    \tau_{\alpha_0} &\rho_{{\alpha_0}{\alpha_1}} \\ 
    \rho_{{\alpha_0}{\alpha_1}} &\tau_{\alpha_1}
  \end{bmatrix}\right), \\
  \gamma_0 &\sim \text{Normal}(0, \tau_{\gamma_0}).
\end{align*}

```{r}
#| label: model-estimate
#| cache: false

contrasts(dat$post) <- c(-0.5, 0.5)

model <- bf(mood | cens(cl) ~ 1 + post + (1 + post | pid) + (1 | ps)) +
  gaussian()

fit <- brm(
  model,
  data = dat,
  silent = 0,
  threads = 2,
  iter = 2000,
  control = list(adapt_delta = .95),
  file = "models/brm-pre-post-pid-ps-censored"
)
```

```{r}
#| label: model-convergence
#| eval: false

library(posterior)
as_draws(fit, variable = c("b_", "sd_", "cor_"), regex = TRUE) |> 
  summarise_draws(rhat)
pairs(fit$fit, pars = variables(fit)[1:7])
```

We analyzed the data with R [@rcoreteamLanguageEnvironmentStatistical2023] and used the brms package to estimate, via Stan's HMC sampling procedures, and post-process the models [@@burknerBrmsPackageBayesian2017; @standevelopmentteamStanModelingLanguage2022]. We drew `r number2(ndraws(fit))` samples from the posterior distribution using brms' default prior distributions on all parameters, and used numerical and graphical checks to ensure model convergence and adequacy.

# Results

## Descriptives

```{r}
#| label: fig-descriptives
#| include: true
#| fig-height: 2.2
#| fig-width: 7
#| fig-cap: '**A**. Histogram of session durations (note log10 x-axis). **B**. Summary of how many sessions each participant completed. **C**. Histogram of all mood ratings.'

p0 <- dat |>
  ggplot() +
  scale_x_continuous(
    expand = expansion(c(0.01, 0.01)),
  ) +
  scale_y_continuous(
    expand = expansion(c(0.001, 0.1)),
  ) +
  geom_histogram(
    col = "white",
    linewidth = .25
  )

dat_session_durations <- dat |>
  filter(duration == max(duration), .by = c(pid, session))

dat_session_counts <- dat |>
  distinct(pid, session) |>
  count(pid, name = "sessions")

p_durations <- p0 %+%
  dat_session_durations +
  aes(duration) +
  scale_x_log10() +
  labs(x = "Session duration (minutes)", y = "Sessions")


p_sessions <- p0 %+%
  dat_session_counts +
  coord_cartesian(xlim = c(0, 15)) +
  aes(sessions) +
  labs(x = "Sessions", y = "Participants")

p_mood <- p0 +
  aes(mood) +
  labs(x = "Mood", y = "Responses")


(p_durations | p_sessions | p_mood) +
  plot_annotation(tag_level = "A")
```

```{r}
probs <- c(.5, .1, .9)
tmp <- list()
tmp$a <- quantile(dat_session_durations$duration, probs = probs, na.rm = TRUE)
tmp$b <- quantile(dat_session_counts$sessions, probs = probs, na.rm = TRUE)
tmp$c <- quantile(dat$mood, probs = probs, na.rm = TRUE)
tmp$d <- quantile(dat$mood[dat$post == 0], probs = probs, na.rm = TRUE)
tmp$e <- quantile(dat$mood[dat$post == 1], probs = probs, na.rm = TRUE)
```

The median session duration was `r tmp$a` minutes [10 and 90 percentiles] (@fig-descriptives A); the median player contributed data from `r tmp$b` sessions (@fig-descriptives B), and the median mood was `r tmp$c` (@fig-descriptives C; pre-session: `r tmp$d`, during play: `r tmp$e`). 

```{r}
#| label: fig-data
#| include: true
#| fig-width: 8
#| fig-height: 5
#| fig-cap: "**A**. Representative data from three participants (rows) showing scatterplots of mood responses over that session's (columns) duration. Each session's first mood report is highlighted in red, subsequent reports are in blue. **B**. Horizontal histograms of all sessions' mood response for that person. **C**. Scatterplot of person-mean mood reports at the beginning of the session (x-axis) and subsequent reports (y-axis). **D**. Histograms of mood ratings at the beginning of session, during the session, and differences between person-means of first and subsequent mood reports."

axislabels <- c(0, 0.5, 1.0)

# Take a quasirandom sample of people who had sufficient number of sessions
# and data per session.
set.seed(99)
tmp <- dat |>
  add_count(pid, session, name = "obs_per_session") |>
  filter(obs_per_session >= 4) |>
  mutate(session = as.numeric(as.factor(session)), .by = pid) |>
  mutate(session_per_person = length(unique(session)), .by = pid) |>
  filter(session_per_person >= 4) |>
  arrange(pid, session) |>
  filter(pid %in% sample(unique(pid), 3)) |>
  mutate(Session = str_glue("Session {session}"), Person = str_glue("Person {fct_anon(pid)}"))

library(ggdist)
p_mood_duration_sessions <- tmp |> 
  ggplot() +
  aes(duration / 60, mood, col = post) +
  scale_color_brewer(
    "Pre-session measure",
    palette = "Set1",
    aesthetics = c("color", "fill")
  ) +
  scale_x_continuous(
    "Session duration (hours)"
  ) +
  scale_y_continuous(
    "Mood",
    limits = c(0, 1),
    breaks = axislabels,
    labels = axislabels
  ) +
  geom_point(size = 1.5, alpha = 1) +
  facet_grid(
    rows = vars(Person), 
    cols = vars(Session),
    scales = "free_x"
  ) +
  theme(
    legend.position = "none",
    strip.text.y = element_blank()
  )

p_mood_duration_all <- tmp |> 
  mutate(Session = "All sessions") |> 
  ggplot() +
  aes(y = mood, col = post, fill = post) +
  scale_color_brewer(
    "Pre-session measure",
    palette = "Set1",
    aesthetics = c("color", "fill")
  ) +
  scale_x_continuous(
    "Scaled count",
    expand = expansion(c(0.01, 0.1))
  ) +
  scale_y_continuous(
    limits = c(0, 1),
    breaks = axislabels,
    labels = axislabels
  ) +
  geom_dotplot(
    aes(x = 0),
    dotsize = 0.9,
    binaxis = "y",
    method = "histodot",
    binwidth = 0.06,
    stackgroups = TRUE
  ) +
  facet_grid(
    rows = vars(Person), 
    cols = vars(Session)
  ) +
  theme(
    axis.text = element_blank(), 
    axis.title.y = element_blank(), 
    axis.ticks.y = element_blank(), 
    strip.background.y = element_blank(),
    legend.position = "none"
  )

p_mood_duration <- (p_mood_duration_sessions | p_mood_duration_all) +
  plot_layout(widths = c(5/6, 1/6))

tmp <- dat |> 
  summarise(
    mood = mean(mood, na.rm = TRUE),
    .by = c(pid, post)
  ) |> 
  pivot_wider(names_from = post, values_from = mood) |> 
  mutate(delta = `1` - `0`)

p_mood_biscatter <- tmp |> 
  ggplot(aes(`0`, `1`)) +
  scale_x_continuous(
    "Pre-session mood",
    expand = expansion(0.01),
    breaks = axislabels,
    labels = axislabels
  ) +
  scale_y_continuous(
    "Mood during session",
    expand = expansion(0.01),
    breaks = axislabels,
    labels = axislabels
  ) +
  geom_point(
    alpha = .25, size = 1, shape = 1
  ) +
  geom_abline(linewidth = .33, col = "dodgerblue") +
  theme(aspect.ratio = 1)

p_mood_difference <- tmp |> 
  rename(
    `Pre-session` = `0`,
    `During session` = `1`,
    `Difference (During - Pre)` = delta
  ) |> 
  pivot_longer(-pid) |> 
  mutate(name = fct_inorder(name)) |> 
  ggplot(aes(value)) +
  geom_histogram(bins = 30, col = "white") +
  scale_y_continuous(
    "Participants",
    expand = expansion(c(0.001, 0.1))
  ) +
  scale_x_continuous(
    "Mood",
    expand = expansion(c(0.001))
  ) +
  facet_wrap("name", ncol = 3, scales = "free")

(p_mood_duration / (p_mood_biscatter | p_mood_difference)) +
  plot_layout(heights = c(6, 4)) +
  plot_annotation(tag_level = "A")
```

```{r}
#| label: tbl-avg
#| include: true
#| tbl-cap: Population level average mood at beginning and during a game play session, and their difference (during - pre-play). (Estimate = posterior mean, CI = 95% quantile interval, pd = probability of direction.)

hs <- c(
  "Pre-play" = "Intercept + post1 * -.5 = 0",
  "During play" = "Intercept + post1 * .5 = 0",
  "Difference" = "post1 = 0"
)

h_avg_ <- hypothesis(fit, hs)
h_avg <- tibble(h_avg_$samples)
names(h_avg) <- names(hs)
h_avg |> 
  summarise_draws(
    mean = ~number(mean(.), .001), 
    ~number2(quantile2(., probs = c(.025, .975)), .001), 
    pd = ~percent2(Pr(. > 0))
  ) |> 
  mutate(CI = str_glue("[{q2.5}, {q97.5}]")) |> 
  select(` ` = variable, Estimate = mean, CI, pd) |> 
  knitr::kable()
```

We then turned to our primary research question: To what extent does player mood in PWS change from pre-play to during play? First, we visualize the relevant data in (@fig-data): Panel A shows mood responses from three example participants' first five sessions of play. @fig-data B then shows histograms of those data to facilitate visual comparison of the raw data. We then calculated participants' mean moods at the beginning and during each session (@fig-data C): Visual inspection shows a considerable shift toward higher values for the during play means. @fig-data D shows histograms of the pre- and during play mood means, and their difference, and suggests that while many differences are small, overall mean moods appeared greater during play than pre-play.

The model results confirmed the visual impressions described above: @tbl-avg indicates, with great certainty, that mood increased by about [`r paste0(map(h_avg_$hypothesis[3,4:5], ~number(.x, .001)), collapse = ", ")`] units. 

```{r}
#| label: scaled-coefficients
#| eval: false

library(latex2exp)
tmp_ <- as_draws_df(
  fit, 
  c("sd_pid__Intercept", "sd_pid__post1", "sigma", "b_post1")
) |> 
  mutate(
    total_residual = sd_pid__Intercept + sd_pid__post1 + sigma,
    z0 = b_post1 / total_residual,
    z1 = b_post1 / sd_pid__Intercept,
    z2 = b_post1 / sd_pid__post1,
    z3 = b_post1 / sigma
  )

tmp <- tmp_ |> 
  summarise_draws(
    mean = ~number(mean(.), .001), 
    ~number2(quantile2(., probs = c(.025, .975)), .001)
  ) |> 
  mutate(
    x = str_glue("{mean} [{q2.5}, {q97.5}]")
  )
tmp_ |> 
  select(b_post1, starts_with("z")) |> 
  pivot_longer(everything()) |> 
  ggplot(aes(value, name)) +
  stat_slabinterval(
    .width = c(.8, .95),
    normalize = "xy",
    height = .5,
    interval_size_range = c(0.5, 1),
    fatten_point = 1
  ) +
  scale_x_continuous(
    "Contrast magnitude",
    breaks = scales::extended_breaks(7)
  ) +
  scale_y_discrete(
    labels = c(
      TeX(r"($\alpha_1$)"),
      TeX(r"($\frac{\alpha_1}{\tau_0 + \tau_1 + \sigma}$)"),
      TeX(r"($\frac{\alpha_1}{\tau_0}$)"),
      TeX(r"($\frac{\alpha_1}{\tau_1}$)"),
      TeX(r"($\frac{\alpha_1}{\sigma}$)")
    ),
    expand = expansion(0.1)
  ) +
  theme(
    axis.title.y = element_blank()
  )

coef(fit, summary = FALSE)$pid[,,"post1"] |> 
  as_tibble()

fixef(fit, summary = FALSE)[,"post1", drop = FALSE] |> 
  as_tibble()
```

To further interpret the magnitude of the difference in moods between pre- and during play, we compared the contrast to the natural variations in mood as estimated by the model. Specifically, we compared the estimated pre - during contrast to the standard deviation of the between-person differences in the intercept ($\tau_{\alpha_0}$ = `r tmp$x[1]`), the contrast ($\tau_{\alpha_1}$ = `r tmp$x[2]`) and to the residual within-person variation ($\sigma$). 


# Bibliography

::: {#refs}
:::
