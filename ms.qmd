---
date: 2023-07-18
bibliography: bibliography.bib
format:
  docx:
    reference-doc: reference.docx
  pdf:
    keep-tex: false
    documentclass: scrartcl
    classoption: twocolumn
    fontfamily: libertinus
    fontsize: 10pt
    papersize: a4
    fig-align: center
    fig-width: 8
    section-number: true
    geometry:
      - top=20mm
      - left=20mm
      - right=20mm
      - bottom=30mm
    include-in-header:
      - text: |
          \setlength{\columnsep}{7.5mm}
          \addtokomafont{disposition}{\normalfont}
---

```{r setup}
#| include: false

knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  cache = TRUE,
  include = FALSE,
  echo = FALSE
)
```

```{r packages}
#| cache: false
library(scales)
library(cmdstanr)
library(brms)
library(ggstance)
library(patchwork)
library(tidyverse)
```

```{r options}
#| cache: false

dir.create("models", FALSE)
options(
  mc.cores = 8,
  brms.backend = "cmdstanr"
)
theme_set(
  theme_linedraw(base_size = 10) +
    theme(
      strip.background = element_rect(fill = NA, color = NA), 
      strip.text = element_text(colour = "black", hjust = 0), 
      axis.text = element_text(size = rel(0.75)),
      panel.grid = element_blank()
    )
)
```

```{r functions}
# Format big numbers with a comma
number2 <- function(x, ...) {
  number(x, ..., big.mark = ",")
}
# Replace extreme percentages
percent2 <- function(x, accuracy = .1) {
  x <- percent(x, accuracy = accuracy)
  x <- if_else(x == "100.0%", ">99.9%", x)
  x <- if_else(x == "0.0%", "<0.1%", x)
  x
}
```

```{r}
#| label: data-download

# Download, unzip data from OSF PWS database
path <- "data-raw/data.zip"
if (!file.exists(path)) {
  download.file("https://osf.io/download/j48qf/", destfile = "data-raw/data.zip")
  dir.create("data", FALSE)
  unzip(path, files = c("data/demographics.csv", "data/study_prompt_answered.csv"))
}
```

# Methods

```{r data-load}
# Load data from csv
dat <- read_csv(
  "data/study_prompt_answered.csv",
  col_select = c(
    pid, 
    time = Time_utc, 
    duration = CurrentSessionLength,
    prompt = LastStudyPromptType, 
    mood = response
  )
) |> 
  mutate(
    pid = factor(pid),
    mood = mood / 1000
  )

# Calculate raw data summaries
sraw <- list()
sraw$n_res <- dat |> 
  count(prompt) 
sraw$n_res_total <- number2(sum(sraw$n_res$n))
sraw$n_res <- sraw$n_res |> 
  mutate(n = number2(n)) |> 
  pivot_wider(names_from = prompt, values_from = n)
sraw$n_sub <- number2(length(unique(dat$pid)))

# Create sessions using heuristics below
dat <- dat |> 
  arrange(pid, time) |> 
  mutate(
    i = row_number(),
    # Observation is in a new session if this...
    new_session = 
      # is the first total observation,
      i == 1 |
      # session duration is zero,
      (duration == 0) | 
      # session duration is less than previous session duration (ticker has reset),
      (duration < lag(duration, default = 0)) | 
      # or if more than 30 minutes since previous observation.
      (time > lag(time) + minutes(30)),
    # Session number is the cumulative sum of new sessions...
    session = cumsum(new_session),
    # ... per person
    .by = pid
  ) |> 
  select(-c(i, new_session))


# Filter data: Just wellbeing responses that occurred in sessions with both "pre" and "post" measures
dat <- dat |> 
  filter(prompt == "Wellbeing") |> 
  select(-prompt)

# Count of data with all wellbeing observations
dat_total <- dat |> 
  summarise(
    n_total = n(),
    n_players = length(unique(pid))
  )

# Include only sessions with "pre-" and "post" measure(s)
dat <- dat |> 
  filter(
    # Session has a wellbeing measure at time = 0
    duration[1] == 0, 
    # Session has at least two non-missing wellbeing measures (e.g. pre + 1 post)
    sum(!is.na(mood)) > 1,
    .by = c(pid, session)
  )

# Count of data to be used in these analyses  
dat_filtered <- dat |> 
  summarise(
    n_total = n(),
    n_players = length(unique(pid))
  )

# Summary
bind_rows(
  "total" = dat_total,
  "filtered" = dat_filtered,
  .id = "Data"
)

# Summaries of filtered data
s <- list()
s$n_sub <- number2(length(unique(dat$pid)))
s$n_obs <- number2(nrow(dat))
s$n_obs_missing <- number2(nrow(filter(dat, is.na(mood))))
s$n_ses <- number2(nrow(count(dat, pid, session)))
```

## Participants

```{r demographics-load}
demo <- read_csv(
  "data/demographics.csv", 
  col_select = c(pid, country, gender, age)
) |> 
  filter(pid %in% unique(dat$pid))

a <- quantile(demo$age, probs = c(.5, .1, .9), na.rm = TRUE)
a <- str_glue("{a[1]} ({a[2]}, {a[3]})")
g <- count(demo, gender, sort = TRUE) |> 
  mutate(p = n / sum(n)) |> 
  mutate(x = str_glue("{gender} ({number2(n)}, {percent2(p)})"))
n_countries <- length(unique(demo$country[!is.na(demo$country)]))
countries <- count(demo, country, sort = TRUE) |> 
  mutate(p = n / sum(n)) |> 
  mutate(x = str_glue("{country} ({number2(n)}, {percent2(p)})"))
```

The PowerWash Simulator case study database contains `r sraw$n_res_total` psychological item responses from `r sraw$n_sub` individuals. In this study, we only studied subjective well-being (mood), so did not consider the other five types of item responses in the database (enjoyment, focus, autonomy, competence, and immersion). Therefore, here we used data from `r s$n_sub` participants who provided `r s$n_obs` mood responses (`r s$n_obs_missing` with missing values) from `r s$n_ses` gameplay sessions.

These participants median age (1st & 9th deciles) was `r a`, and four most frequent responses to gender were `r g$x[1:4]`. They hailed from `r n_countries`, with four most represented countries being `r countries$x[1:4]`.

The study procedures were granted ethical approval by Oxford Universityâ€™s Central University Research Ethics Committee (SSH_OII_CIA_21_011). All participants provided informed consent to participate and reported being 18 years or older.

## Measures

We measured affective well-being with one item.

## Data analysis

```{r}
dat <- dat |> 
  mutate(
    post = factor(
      row_number() > 1, 
      levels = c(FALSE, TRUE), 
      labels = c("0", "1")
    ),
    .by = c(pid, session)
  ) |> 
  mutate(ps = interaction(pid, session, sep = "_")) |> 
  mutate(
    cl = case_when(
      mood == 0 ~ "left",
      mood == 1 ~ "right",
      TRUE ~ "none"
      )
  )
```

The focal inference in the current work were mood levels at the beginning of each session (during those subset of sessions where mood was queried at login) contrasted to mood levels during the subsequent play session. We modelled each mood report *i* in 1 to `r nrow(dat)` for participant *j* in 1 to `r length(unique(dat$pid))` and participant-session *k* in 1 to `r length(unique(dat$ps))` as normally distributed with the following equations:

$$
\begin{align*}
\text{mood}_{ijk} &\sim \text{Normal}(\eta_{ijk}, \kappa_{ij}), \\
\eta_{ijk} &= \alpha_0 + \beta_{0j} + \gamma_{0k} + \\ 
  &\quad \ (\alpha_1 + \beta_{1j} + \gamma_{1k})\text{post}_{ijk}, \\
log(\kappa_{ij}) &= \alpha_2 + \beta_{2j} + \alpha_3\text{post}_{ijk}, \\
\begin{bmatrix} \alpha_0 \\ \alpha_1 \\ \alpha_2 \end{bmatrix} &\sim 
  \text{MVN}\left(\begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix}, 
  \begin{bmatrix} 
    \tau_{\alpha_0} &\rho_{{\alpha_0}{\alpha_1}} &\rho_{{\alpha_0}{\alpha_2}} \\ 
    \rho_{{\alpha_0}{\alpha_1}} &\tau_{\alpha_1} &\rho_{{\alpha_1}{\alpha_2}} \\ 
    \rho_{{\alpha_0}{\alpha_2}} &\rho_{{\alpha_1}{\alpha_2}} &\tau_{\alpha_2} 
  \end{bmatrix}\right), \\
  \begin{bmatrix} \gamma_0 \\ \gamma_1 \end{bmatrix} &\sim
    \text{MVN}\left(\begin{bmatrix} 0 \\ 0 \end{bmatrix}, 
    \begin{bmatrix} 
      \tau_{\gamma_0} &\rho_{{\gamma_0}{\gamma_1}} \\ 
      \rho_{{\gamma_0}{\gamma_1}} &\tau_{\gamma_1}
  \end{bmatrix}\right).
\end{align*}
$$

We analyzed the data with R [@rcoreteamLanguageEnvironmentStatistical2023] and used the brms package for models [@burknerBrmsPackageBayesian2017].

```{r}
contrasts(dat$post) <- c(-0.5, 0.5)
model <- bf(mood | cens(cl) ~ 0 + post + (0 + post |p| pid) + (1 | ps)) +
  lf(sigma ~ 0 + post + (1 |p| pid)) +
  gaussian()

get_prior(model, dat)

fit <- brm(
  model,
  data = dat |> filter(pid %in% sample(unique(dat$pid), 100)),
  silent = 0,
  threads = 2,
  iter = 750,
  control = list(adapt_delta = .9),
  file = "models/brm"
)
summary(fit, prior = TRUE)
```

# Results

## Descriptives

```{r}
#| label: fig-descriptives
#| include: true
#| fig-height: 2.2
#| fig-width: 7
#| fig-cap: '**A**. Histogram of session durations. **B**. Summary of how many sessions each participant completed. **C**. Histogram of all mood ratings.'

p0 <- dat |> 
  ggplot() +
  scale_x_continuous(
    expand = expansion(c(0.01, 0.01)),
  ) +
  scale_y_continuous(
    expand = expansion(c(0.001, 0.1)),
  ) +
  geom_histogram(
    col = "dodgerblue4",
    fill = "dodgerblue1",
    linewidth = .25
  )

dat_session_durations <- dat |> 
  filter(duration == max(duration), .by = c(pid, session))

dat_session_counts <- dat |> 
  distinct(pid, session) |> 
  count(pid, name = "sessions")
  summarise(
    sessions = max(session),
    .by = pid
  )

p_durations <- p0 %+%
  dat_session_durations +
  aes(duration) +
  scale_x_log10() +
  labs(x = "Session duration (minutes)", y = "Sessions")


p_sessions <- p0 %+% 
  dat_session_counts +
  aes(sessions) +
  labs(x = "Sessions", y = "Participants")

p_mood <- p0 +
  aes(mood) +
  labs(x = "Mood", y = "Responses")


(p_durations | p_sessions | p_mood) +
  plot_annotation(tag_level = "A")
```


```{r}
#| label: fig-data
#| include: true
#| fig-width: 7.2
#| fig-height: 6
#| fig-cap: "**A**. Representative data from three participants (rows) showing scatterplots of mood responses over that session's (columns) duration. Each session's first mood report is highlighted in red, subsequent reports are in blue. **B**. Scatterplot of person-mean mood reports at the beginning of the session (x-axis) and subsequent reports (y-axis). **C**. Histogram of differences between person-means of initial and subsequent mood reports."

axislabels <- c(0, 0.5, 1.0)

# Take a quasirandom sample of people who had sufficient number of sessions
# and data per session.
set.seed(99)
p0 <- dat |> 
  add_count(pid, session, name = "obs_per_session") |> 
  filter(obs_per_session >= 4) |> 
  mutate(session = as.numeric(as.factor(session)), .by = pid) |> 
  mutate(session_per_person = length(unique(session)), .by = pid) |> 
  filter(session_per_person >= 4) |> 
  arrange(pid, session) |> 
  filter(pid %in% sample(unique(pid), 3)) |> 
  mutate(Session = session, Person = fct_anon(pid)) |> 
  ggplot() +
  aes(duration, mood, col = post) +
  scale_color_brewer(
    "Pre-session measure",
    palette = "Set1",
    aesthetics = c("color", "fill")
  ) +
  scale_x_continuous(
    "Session duration (minutes)"
  ) +
  scale_y_continuous(
    "Mood",
    limits = c(0, 1),
    breaks = axislabels,
    labels = axislabels
  ) +
  geom_point(size = 1.5, alpha = .75) +
  facet_grid(
    Person ~ Session
  ) +
  theme(legend.position = "none")

tmp <- dat |> 
  summarise(
    mood = mean(mood, na.rm = TRUE),
    .by = c(pid, post)
  ) |> 
  pivot_wider(names_from = post, values_from = mood) |> 
  mutate(delta = `1` - `0`)
pa <- tmp |> 
  ggplot(aes(`0`, `1`)) +
  scale_x_continuous(
    "First mood",
    expand = expansion(0.01),
    breaks = axislabels,
    labels = axislabels
  ) +
  scale_y_continuous(
    "Subsequent mood",
    expand = expansion(0.01),
    breaks = axislabels,
    labels = axislabels
  ) +
  geom_abline(linewidth = .5, col = "dodgerblue") +
  geom_point(
    alpha = .25, size = 1, shape = 1
  ) +
  theme(aspect.ratio = 1)
pb <- tmp |> 
  drop_na(delta) |> 
  ggplot(aes(delta)) +
  scale_y_continuous(
    "Participants",
    expand = expansion(c(0, 0.1))
  ) +
  scale_x_continuous(
    "Difference (subsequent - first mood)"
  ) +
  geom_histogram(binwidth = .025, col = "white") +
  stat_summaryh(
    fun.data = mean_cl_boot_h, 
    aes(y = 5), 
    col = "dodgerblue"
  )
(p0 / (pa | pb)) +
  plot_layout(heights = c(6, 4)) +
  plot_annotation(tag_level = "A")
```

```{r}
summary(fit)

hs <- c(
  "Pre" = "post0 = 0",
  "Post" = "post1 = 0",
  "Difference" = "post1 - post0 = 0"
)
tmp <- bind_rows(
  hypothesis(fit, hs)$hypothesis,
  hypothesis(fit, hs, scope = "coef", group = "pid")$hypothesis
)
tmp |> 
  ggplot(aes(Estimate, Hypothesis)) +
  geom_point(
    data = . %>% filter(is.na(Group)),
    size = 1
  ) +
  geom_point(
    data = . %>% filter(!is.na(Group)),
    size = .25
  )

```


# Bibliography

::: {#refs}
:::

# Appendices / supplementary analyses / stuff


