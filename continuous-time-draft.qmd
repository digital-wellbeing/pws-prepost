---
title: "Continuous time"
date: now
author: Kristoffer Magnusson
format:
  html:
    code-fold: true
---

```{r}
#| label: setup
#| include: false
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  cache = TRUE,
  include = TRUE,
  echo = TRUE
)
```

```{r}
#| label: packages
#| cache: false
library(patchwork)
library(tidyverse)
library(lme4)
library(knitr)
library(emmeans)
library(splines)
```


Data cleaning copied from `ms.qmd` to create sessions and the pre/post contrast.
```{r}
#| label: options
#| cache: false
dat <- read_rds("data/session.rds")
dat2 <- dat |>
  filter(prompt == "Wellbeing") |>
  select(-prompt)

dat2 <- dat2 |>
  filter(
    # Session has a wellbeing measure at time = 0
    duration[1] == 0,
    # Session has at least two non-missing wellbeing measures 
    # (e.g. pre + 1 post)
    sum(!is.na(mood)) > 1,
    .by = c(pid, session)
  )

dat2 <- dat2 |>
  mutate(
    post = factor(
      row_number() > 1,
      levels = c(FALSE, TRUE),
      labels = c("0", "1")
    ),
    .by = c(pid, session)
  ) |>
  mutate(ps = interaction(pid, session, sep = "_")) |>
  mutate(
    cl = case_when(
      mood == 0 ~ "left",
      mood == 1 ~ "right",
      TRUE ~ "none"
    )
  )
```

## Exploring sessions
Let's look at one participant and compare the pre/post data set to the complete data. 

```{r}
#| label: fig-duration
#| fig-cap: Comparing full data (top) with pre-post (bottom) data
p0 <- ggplot(
  filter(dat, 
    pid == "p6622",
    session %in% 14:16
    ),
  aes(
    time,
    session,
    group = session
  )
) + 
  geom_point(
    aes(color = factor(prompt == "Wellbeing")),
    size = 2
    ) +
  scale_x_datetime(limits = c(ymd_hms("2022-09-19 16:00:00"), ymd_hms("2022-09-20 00:00:00"))) +
  scale_y_continuous(breaks = 14:16) +
  facet_wrap(~pid)

p1 <- ggplot(
  filter(dat2, 
    pid == "p6622",
    session %in% 14:16
    ),
  aes(
    time,
    session,
    group = session
  )
) + 
  geom_point(
    aes(color = factor(post)),
    size = 2
    ) +
  scale_x_datetime(limits = c(ymd_hms("2022-09-19 16:00:00"), ymd_hms("2022-09-20 00:00:00"))) +
  scale_y_continuous(breaks = 14:16) +
  facet_wrap(~pid)
p0 / p1
```

## Concerns with the pre/post contrast.
There are issues with the pre/post contrasts.

### 1. Session duration doesn't always start at 0
As can be seen in @fig-duration, session 16 isn't included in the pre/post data, even tho the first response is a WB prompt. This is because it's duration is 6. 
```{r}
filter(dat, 
  pid == "p6622",
  session %in% 14:16
) %>% 
kable()

filter(dat2, 
  pid == "p6622",
  session %in% 14:16
) %>% 
kable()
```

### 2. Lot's of data is discarded
As can be seen in the @fig-pre-post there can be lot's of data that is not covered by the pre-post contrast. This might not be a problem as the prompts were randomized. But it's a lot of PWS gameplay that's also ignored.

```{r}
#| label: fig-pre-post
#| fig-cap: Comparing full data (top) with pre-post (bottom) data
p0 <- ggplot(
  filter(dat, 
    pid == "p10",
    session %in% 16:26
    ),
  aes(
    time,
    session,
    group = session
  )
) + 
  geom_point(
    aes(color = factor(prompt == "Wellbeing")),
    size = 2
    ) +
  scale_x_datetime(
    limits = c(
      ymd_hms("2023-02-25 00:00:00"), 
      ymd_hms("2023-02-29 00:00:00"
      )
    )
  ) +
  scale_y_continuous(breaks = 16:26)

p1 <- ggplot(
  filter(dat2, 
    pid == "p10",
    session %in% 16:26
    ),
  aes(
    time,
    session,
    group = session
  )
) + 
  geom_point(
    aes(color = factor(post)),
    size = 2
    ) +
  scale_x_datetime(
    limits = c(
      ymd_hms("2023-02-25 00:00:00"), 
      ymd_hms("2023-02-29 00:00:00")
      )
    ) +
  scale_y_continuous(breaks = 16:26)
p0 / p1
```

### 3. There are multiple post responses within a session
The "post" contrast is the average mood during a session. I know this is intentional, but I'm not sure if it's ideal. I think continuous time would be more interesting. The contrast averages over sessions that are too irregular, and will be hard to interpret. A model with continuous time within sessions would solve this.

```{r}
filter(dat, pid == "p10", session == 16) %>% 
  kable()

filter(dat2, pid == "p10", session == 16) %>% 
  kable()
```

### 4. The post contrast doesn't represent the whole session
This can also be seen in the data above. The last post measure in session 16 is at 2023-02-25 11:31:43, but the actual session continues for at least an hour longer, as can be seen in the full data: 2023-02-25 12:41:00. I'm not sure if this matter, but it feels weird that this isn't captured by the model. I guess this is related to concern #2, I think we need to somehow encode the "dose" of the PWS "treatment", and the planned missingness of the mood prompts.

### The post contrast could be replaced with continuous time
A model of the form

```r
mood ~ spline(time, knots) + (1 | session) + (1 | id)
```

would allow modeling change during session while still accounting for the highly irregular sessions.

There is also the option to scale time to 1 on a session level to more closely mimic a pre/post design. This would have the advantage of being able to include all wellbeing responses, regardless if a session starts with a wellbeing measure.

### Session lengths

What's the distribution of session lengths
```{r}
median_ses_len <- dat %>% 
  group_by(pid, session) %>% 
  mutate(
    duration = duration - duration[1],
  ) %>% 
  summarise(session_length = max(duration)) %>% 
  group_by(pid) %>% 
  summarise(median_len = median(session_length))
median(median_ses_len$median_len)
mean(median_ses_len$median_len > 60)
```

"Typical" session length is 35 minutes. Few participants typically play for more than an hour. Plot estimated trend over 0 to 2 hours.

### Fit model
Reset duration within each session
```{r}
dat <- dat %>%
  mutate(
    ps = interaction(pid, session, sep = "_")
  )  %>% 
  filter(prompt == "Wellbeing") %>% 
  mutate(
    duration = duration - duration[1],
    hours = duration / 60,
    .by = c(pid, session)
  ) 
write_rds(dat, "data/ct-dev-data.rds")
```


Fit linear change
```{r}
#| code-fold: show
library(rms)
fit0 <- lmer(mood ~ hours + (1 | ps) + (1 | pid), data = dat)
```



```{r}
emm0 <- emmeans(
  fit0, 
  ~hours, 
  at = list(hours = seq(0,2, length.out = 100)),
  lmer.df = "asymptotic"
  )

p0 <- as.data.frame(emm0) %>% 
  ggplot(aes(hours, emmean)) + 
  geom_line() +
  geom_ribbon(aes(ymin = asymp.LCL, ymax = asymp.UCL), alpha = 0.25) +
  labs(x = "Session duration (hours)")
```


Let's try non-linear change using `rms::rcs` with 5 knots with default placement, which should place most knots during the first hour.
```{r}
attr(rcs(dat$hours, 5), "parms")
```

Fit model with only random intercepts.
```{r}
#| code-fold: show
fit1 <- lmer(mood ~ rcs(hours, 5) + (1 | ps) + (1 | pid), data = dat)
```

```{r}
emm1 <- emmeans(
  fit1, 
  ~hours, 
  at = list(hours = seq(0,2, length.out = 100)),
  lmer.df = "asymptotic"
  )

## for plotting knot placement
get_knot_coords <- function(fit) {
    knots <- attr(rcs(dat$hours, 5), "parms")
    knots_x <- rcs(knots, knots)
    b0 <- fixef(fit)[1]
    b <- fixef(fit)[-1]
    knots_y <- b0 + knots_x[,1] * b[1] + knots_x[,2] * b[2] + knots_x[,3] * b[3] + knots_x[,4] * b[4]
    data.frame(
        x = knots,
        y = c(knots_y)
    )
}
p1 <- as.data.frame(emm1) %>% 
  ggplot(aes(hours, emmean)) + 
  geom_line() +
  geom_ribbon(aes(ymin = asymp.LCL, ymax = asymp.UCL), alpha = 0.25) +
  geom_point(
    data = get_knot_coords(fit1),
    aes(x,y)
  ) +
  labs(x = "Session duration (hours)")
```

Adding `rcs(hours, 5)` as random effects would be messy, so let's fit the model with a linear random slope at the participant level. I don't think random slopes at the session level is needed? Moreover, I would expect that the exact random slopes specification have little impact on fixed effects in this case.

```{r}
#| code-fold: show
path <- "models/lmm-fit2.Rds"
if (file.exists(path)) {
  fit2 <- read_rds(path)
} else {
  fit2 <- lmer(mood ~ rcs(hours, 5) + (1 | ps) + (1 + hours | pid), data = dat)
  write_rds(fit2, path)
}
```

```{r}
emm2 <- emmeans(
  fit2, 
  ~hours, 
  at = list(hours = seq(0,2, length.out = 100)),
  lmer.df = "asymptotic"
  )
p2 <- as.data.frame(emm2) %>% 
  ggplot(aes(hours, emmean)) + 
  geom_line() +
  geom_ribbon(aes(ymin = asymp.LCL, ymax = asymp.UCL), alpha = 0.25) +
  # geom_point(
  #   data = get_knot_coords(fit2),
  #   aes(x,y)
  # ) +
  labs(x = "Session duration (hours)")
```

Plots models, ignore model 2 as it's basically identical to model 1.

```{r}
p0 / p1 / p2
```

I think the shape of the spline makes sense.


## YOLO model with random slopes
Here I add a random slope to each piece of the spline, i.e. 4 random slopes at the participant level. The model is fit on a random subset of 1000 pids.
```{r}
#| cold-fold: show

# include 1000 participants
set.seed(1337)
pids <- sample(unique(dat$pid), 1000)
tmp <- filter(dat, pid %in% pids)
# so predict won't complain
tmp <- tmp %>% 
    mutate(
        pid = as.integer(pid),
        ps = as.integer(ps)
        )
# same spline but different parameterization
# usually less estimation problems
spline <- ns(
    tmp$hours, 
    knots = c(0.12, 0.4, 1), 
    Boundary.knots = c(0.016, 3)
)
colnames(spline) <- paste0("hours", 0:3)
tmp <- cbind(tmp, spline)
path <- "models/lmm-fit3.Rds"
if (file.exists(path)) {
  fit3 <- read_rds(path)
} else {
  fit3 <- lmer(
    mood ~ hours0 + hours1 + hours2 + hours3 + (1 | ps) + (1 + hours0 + hours1 + hours2 + hours3 | pid), 
    data = tmp
  )
  write_rds(fit3, path)
}

```

I'm interested in if the spline changes based on the pre-session scores. Let's plot the fixed effects at -2, -1, 0 times the random intercept SD + the corresponding random slope values based on their correlation with the random intercept. 

```{r}
get_trend <- function(fit, data, re_int = 0, re_s0 = 0, re_s1 = 0, re_s2 = 0, re_s3 = 0) {
    hours <- seq(0,2, length.out = 100)
    x <- ns(
        hours, 
        knots = c(0.12, 0.4, 1), 
        Boundary.knots = c(0.016, 3)
    )
    b0 <- fixef(fit)[1] + re_int
    b <- fixef(fit)[-1] 
    y <- b0 + x[,1] * (b[1] + re_s0) + x[,2] * (b[2] + re_s1) + x[,3] * (b[3] + re_s2) + x[,4] * (b[4] + re_s3)
    data.frame(
        x = hours,
        y = c(y),
        re_int
    )
}
re <- as.data.frame(VarCorr(fit3))
pid_int <- re[2, "sdcor"]
pid_slope0 <- re[3, "sdcor"]
pid_slope1 <- re[4, "sdcor"]
pid_slope2 <- re[5, "sdcor"]
pid_slope3 <- re[6, "sdcor"]
pid_cor0 <- re[7, "sdcor"]
pid_cor1 <- re[8, "sdcor"]
pid_cor2 <- re[9, "sdcor"]
pid_cor3 <- re[10, "sdcor"]
sd1 <- 1
sd2 <- 2
rbind(
    get_trend(fit3, data = tmp),
    get_trend(
        fit3, 
        data = tmp,
        -sd1 * pid_int,
        -sd1 * pid_cor0 * pid_slope0, 
        -sd1 * pid_cor1 * pid_slope1, 
        -sd1 * pid_cor2 * pid_slope2, 
        -sd1 * pid_cor3 * pid_slope3
    ),
    get_trend(
        fit3, 
        data = tmp,
        -sd2 * pid_int,
        -sd2 * pid_cor0 * pid_slope0, 
        -sd2 * pid_cor1 * pid_slope1, 
        -sd2 * pid_cor2 * pid_slope2, 
        -sd2 * pid_cor3 * pid_slope3
        )
    ) %>% 
  ggplot(
    aes(
        x, 
        y, 
        color = factor(re_int), 
        group = factor(re_int)
        )
    ) + 
  geom_line() +
  labs(x = "Session duration (hours)")
```

The random intercepts are only weakly correlated with each piece of the cubic spline, so the shape doesn't change much.

Let's also predict some individual slopes.

```{r}
pred <- filter(tmp, pid %in% sample(unique(tmp$pid), 10))
pred$yhat <- predict(fit3, newdata = pred)
ggplot(
    data = pred,
    aes(
        x = hours,
        y = yhat,
        group = ps
    )
) + 
    geom_line(
        color = "blue", 
        linewidth = 1
    ) +
    geom_point(
        aes(y = mood)
    ) +
    facet_wrap(~pid)
```


Zoom in on pid 9263.
```{r}
ggplot(
    data = filter(pred, pid == 9263),
    aes(
        x = hours,
        y = yhat,
        group = ps
    )
) + 
    geom_line(
        aes(y = mood),
        linetype = "dashed",
        alpha = 0.33
    ) +
    geom_line(
        color = "blue", 
        linewidth = 2
        ) +
    geom_point(
        aes(y = mood)
    ) +
    facet_wrap(~session)
```

Probably good enough, even tho the session effect is only modelled using a random intercept.

### Predict change
Another YOLO approach to estimate individual change during a session is to to look at the model predictions.

TODO: should be based on the actual session length, not only the range of WB prompts.

```{r}
pred <- fit3@frame
pred$yhat <- predict(fit3)
pred %>% 
  # compare the last and first value
  dplyr::summarize(change = last(yhat) - yhat[1], .by = c(pid, ps)) %>%
  # average over sessions within participants
  dplyr::summarize(change = mean(change), .by = pid) %>% 
  # average over participants
  dplyr::summarize(mean(change), sd(change))
```

We can also plot the distribution of the participants average change during sessions.
```{r}
pred %>% 
  dplyr::summarize(change = last(yhat) - yhat[1], .by = c(pid, ps)) %>%
  dplyr::summarize(change = mean(change), .by = pid) %>% 
  ggplot(aes(change)) + geom_histogram()
```

They really don't change much. Let's look at a participant out in the tails.
```{r}
pred %>% 
  dplyr::summarize(change = last(yhat) - yhat[1], .by = c(pid, ps))  %>% 
  filter(change > 0.1) %>% head
```

Zoom in on pid 23.
```{r}
pred2 <- filter(tmp, pid == 23)
pred2$yhat <- predict(fit3, newdata = pred2)
ggplot(
    data = pred2,
    aes(
        x = hours,
        y = yhat,
        group = ps
    )
) + 
    geom_line(
        aes(y = mood),
        linetype = "dashed",
        alpha = 0.33
    ) +
    geom_line(
        color = "blue", 
        linewidth = 2
        ) +
    geom_point(
        aes(y = mood)
    ) +
    facet_wrap(~session)
```

This looks kinda reasonable?


## brms
Ignore for now.

```{r}
#| code-fold: show
library(brms)
options(
  mc.cores = 4,
  brms.backend = "cmdstanr"
)
fit_b0 <- brm(
      mood ~ hours0 + hours1 + hours2 + hours3 + (1 | ps) + (1 | pid),
      data = tmp,
      cores = 4,
      file = "models/brm-pre-post-ct0"
)
pp_check(fit_b0)
```


Censoring
```{r}
#| code-fold: show
tmp <- tmp |> 
  mutate(
    cl = case_when(
      mood == 0 ~ "left",
      mood == 1 ~ "right",
      TRUE ~ "none"
    )
  )
fit_b1 <- brm(
      mood | cens(cl) ~ hours0 + hours1 + hours2 + hours3 + (1 | ps) + (1 | pid),
      data = tmp,
      threads = 2,
      iter = 1000,
      file = "models/brm-pre-post-ct1"
)
pp_check(fit_b1)
```


## GAM(M)

Let's try some GAMs. 
```{r}
library(mgcv)
knots <- list(hours = c(0.016, 0.12, 0.4, 1, 3))
tmp <- tmp |> 
  mutate(
    pid = as.factor(pid),
    ps = as.factor(ps)
  )
```

We'll start with a cubic spline using the same knot placement as used with the LMMs.
```{r}
#| code-fold: show
fit_g_0 <- gam(
    mood ~ s(hours, bs = "cr", k = 5), 
    knots = knots,
    method = "REML",
    data = tmp,
)
```

```{r}
plot_gam <- function(fit, t_end = 2) {
  emm0 <- emmeans(
  fit, 
  ~hours, 
  at = list(hours = seq(0, t_end, length.out = 100))
  )

  p0 <- as.data.frame(emm0) %>% 
    ggplot(aes(hours, emmean)) + 
    geom_line() +
    geom_ribbon(aes(ymin = lower.CL, ymax = upper.CL), alpha = 0.25) +
    labs(x = "Session duration (hours)")
  p0
}
plot_gam(fit_g_0)
```

we could add a random intercept for pid and session like this
```{r}
#| eval: false
#| code-fold: show
fit_g_1 <- gam(
    mood ~ s(hours, bs = "cr", k = 5) + s(pid, bs = "re") + s(ps, bs = "re"), 
    knots = knots,
    data = tmp,
)
```

The call above is super slow, so let's use `gamm4` instead.

```{r}
#| code-fold: show
library(gamm4)
fit_g_1_lme4 <- gamm4(
    mood ~ s(hours, bs = "cr", k = 5), 
    knots = knots,
    data = tmp, 
    random = ~ (1 | pid) + (1 | ps)
)
```

```{r}
pred <- data.frame(hours = seq(0,2, length.out = 100))
pred$yhat <- predict(fit_g_1_lme4$gam, newdata = pred)
ggplot(
  pred, 
  aes(hours, yhat)
  ) + 
    geom_line() +
    #geom_ribbon(aes(ymin = lower.CL, ymax = upper.CL), alpha = 0.25) +
    labs(x = "Session duration (hours)")
```

We are using the same smooth for everyone here, which is probably not what we want. 

### Separate smooth per participant
Let's try using a separate smooth per pid. We only fit the model to a subset of participants to save time.

```{r}
#| code-fold: show
set.seed(6666)
tmp2 <- filter(tmp, pid %in% sample(unique(pid), 50)) |> 
  filter(!is.na(mood))
fit_g_by_lme4 <- gamm4(
    mood ~ s(hours, by = pid, bs = "cr", k = 5), 
    knots = knots,
    data = tmp2, 
    random = ~ (1 | pid) + (1 | ps)
)
```

N.B. that only the GAM part is plotted, I'm not sure if there is a command that automagically includes the random effects when using `gamm4`.

```{r}
pred <- expand.grid(
  hours = seq(0, 2, length.out = 100),
  pid = unique(tmp2$pid)
 )
pred$yhat <- predict(fit_g_by_lme4$gam, newdata = pred)
pred$model <- "by"
ggplot(
  pred, 
  aes(
    hours, 
    yhat,
    group = pid,
    color = pid
    )
  ) + 
    geom_line() +
    #geom_ribbon(aes(ymin = lower.CL, ymax = upper.CL), alpha = 0.25) +
    labs(x = "Session duration (hours)") +
    theme(legend.position = "none")

plot_pids <- sample(unique(tmp2$pid), 10)
tmp2 <- filter(tmp2, !is.na(mood))
tmp2$yhat <- predict(fit_g_by_lme4$gam)
tmp2$model <- "by"
ggplot(
  filter(tmp2, pid %in% plot_pids), 
  aes(
    hours, 
    yhat,
    group = ps,
    color = pid
    )
  ) + 
    geom_line(aes(y = mood)) +
    geom_line(color = "blue", linewidth = 1) +
    geom_point(aes(y = mood)) +
    #geom_ribbon(aes(ymin = lower.CL, ymax = upper.CL), alpha = 0.25) +
    labs(x = "Session duration (hours)") +
    facet_wrap(~pid) +
    theme(legend.position = "none")

pred_all <- filter(tmp2, pid %in% plot_pids)
```

We're fitting a separate fixed and random effects for each pid. Fitting this to the full data will be super slow?
```{r}
summary(fit_g_by_lme4$mer)
```


### Factor-smooth interaction 
We can also try a factor-smooth interaction instead, this should be closer to what we want.

```{r}
#| code-fold: show
fit_g_fs_lme4 <- gamm4(
    mood ~ s(hours, pid, bs = "fs", xt = list(bs = "cr"), k = 5, fx = FALSE),, 
    knots = knots,
    data = tmp2, 
    random = ~ (1 | pid) + (1 | ps)
)
```


`gamm4` is not supported by `emmeans`, and I'm not sure how to plot the "marginal" smooth. 

```{r}
pred <- expand.grid(
  hours = seq(0, 2, length.out = 100),
  pid = unique(tmp2$pid)
 )
pred$yhat <- predict(fit_g_fs_lme4$gam, newdata = pred)
pred$model <- "fs"
ggplot(
  pred, 
  aes(
    hours, 
    yhat,
    group = pid,
    color = pid
    )
  ) + 
    geom_line() +
    #geom_ribbon(aes(ymin = lower.CL, ymax = upper.CL), alpha = 0.25) +
    labs(x = "Session duration (hours)") +
    theme(legend.position = "none")

tmp2$yhat <- predict(fit_g_fs_lme4$gam)
tmp2$model <- "fs"
ggplot(
  filter(tmp2, pid %in% plot_pids), 
  aes(
    hours, 
    yhat,
    group = ps,
    color = pid
    )
  ) + 
    geom_line(aes(y = mood)) +
    geom_line(color = "blue", linewidth = 1) +
    geom_point(aes(y = mood)) +
    lims(y = c(0, 1)) +
    #geom_ribbon(aes(ymin = lower.CL, ymax = upper.CL), alpha = 0.25) +
    labs(x = "Session duration (hours)") +
    facet_wrap(~pid) +
    theme(legend.position = "none")
pred_all <- rbind(pred_all, filter(tmp2, pid %in% plot_pids))
```

The smooths in the plot above are all linear. Although, it looks pretty reasonable compared to the observed data. (TODO: investigate with more data.) If we fit a simple smooth to the data it's also linear.

```{r}
#| code-fold: show
gam(
    mood ~ s(hours, bs = "cr", k = 5), 
    knots = knots,
    method = "REML",
    data = tmp2,
) |> 
  plot_gam()

```

### LMM again
As a comparisons, let's refit the LMM with a cubic spline to the subset of data used here. And then we predict without including the random intercepts.

```{r}
#| code-fold: show
fit3 <- lmer(
  mood ~ hours0 + hours1 + hours2 + hours3 + (1 | ps) + (1 + hours0 + hours1 + hours2 + hours3 | pid), 
  data = tmp2
)
```

```{r}
tmp2$yhat <- predict(
  fit3, 
  re.form = ~(0 + hours0 + hours1 + hours2 + hours3 | pid)
)
tmp2$model <- "lmer"
ggplot(
  filter(tmp2, pid %in% plot_pids), 
  aes(
    hours, 
    yhat,
    group = ps,
    color = pid
    )
  ) + 
    geom_line(aes(y = mood)) +
    geom_line(color = "blue", linewidth = 1) +
    geom_point(aes(y = mood)) +
    lims(y = c(0, 1)) +
    #geom_ribbon(aes(ymin = lower.CL, ymax = upper.CL), alpha = 0.25) +
    labs(x = "Session duration (hours)") +
    facet_wrap(~pid)

pred_all <- rbind(pred_all, filter(tmp2, pid %in% plot_pids))
```

### Combined plot
Plot the predictions from the 3 models in a combined figure.

```{r}
#| fig.height: 5
#| fig.width: 7
ggplot(
  pred_all, 
  aes(
    hours, 
    yhat,
    group = interaction(ps, model),
    color = model
    )
  ) + 
    geom_line(data = filter(pred_all, model == "fs"), aes(y = mood, color = NA), alpha = 0.5) +
    geom_point(data = filter(pred_all, model == "fs"), aes(y = mood, color = NA), alpha = 0.5) +
    geom_line(linewidth = 1.5) +
    #lims(y = c(0, 1)) +
    #geom_ribbon(aes(ymin = lower.CL, ymax = upper.CL), alpha = 0.25) +
    labs(x = "Session duration (hours)") +
    facet_wrap(~pid, scales = "free_y")
```

### GAM summary
Assuming that we wanted to fit these smooths in `brms` to model censoring, then

- separate smooths using `by` is not feasible?
- factor-smooth interaction is maybe feasible using the full data.
  - Might be overpenalizing the smooths as they were all straight lines? 
- the LMM is basically in between the model above when it come to "wiggliness", as would be expected

I'm not sure if some if the issues is caused by how GAMs are affected by the highly irregular sessions + missing data.

LMM might be _the_ model?

TODO:

- GAMM?
- Is censoring really needed?
- Visualize the % that have positive vs negative change over a session? or over 30 / 60 minutes.
